# -*- coding: utf-8 -*-
"""CDAC_TEXT_SENTIMENT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xXiC03e_gS7EE9c9o3vvZp-udspMnm--
"""

import pandas as pd
import numpy as np
import re
import nltk
import joblib

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report

nltk.download('stopwords')
from nltk.corpus import stopwords

df = pd.read_csv("train.csv", encoding="latin1")
df.head()

df['sentiment'].value_counts()

df['text'] = df['text'].fillna("")

stop_words = set(stopwords.words('english'))

def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    text = text.split()
    text = [word for word in text if word not in stop_words]
    return ' '.join(text)

df['clean_text'] = df['text'].apply(clean_text)

df['sentiment'] = df['sentiment'].map({
    'negative': 0,
    'neutral': 1,
    'positive': 2
})

X = df['clean_text']
y = df['sentiment']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(
    analyzer='char',
    ngram_range=(3,5),
    min_df=5,
    sublinear_tf=True
)

X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)



models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Naive Bayes": MultinomialNB(),
    "SVM": LinearSVC()
}

for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    preds = model.predict(X_test_tfidf)
    acc = accuracy_score(y_test, preds)
    print(f"{name} Accuracy: {acc:.4f}")

best_model = models["SVM"]

y_pred = best_model.predict(X_test_tfidf)
print(classification_report(y_test, y_pred))

joblib.dump(best_model, "best_sentiment_model.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

"""testing the model"""

test_df = pd.read_csv("test.csv", encoding="latin1")
test_df.head()

test_df.columns





"""testing the model"""

# Load test data
test_df = pd.read_csv("test.csv", encoding="latin1")

# Fill missing text
test_df['text'] = test_df['text'].fillna("")

# ðŸ”¥ CREATE clean_text (THIS WAS MISSING)
test_df['clean_text'] = test_df['text'].apply(clean_text)

# Encode sentiment labels
test_df['sentiment'] = test_df['sentiment'].map({
    'negative': 0,
    'neutral': 1,
    'positive': 2
})

# Drop rows where sentiment is missing
test_df = test_df.dropna(subset=['sentiment'])

# Vectorize test data
X_test_final = vectorizer.transform(test_df['clean_text'])
y_test_final = test_df['sentiment']

# Predict
test_predictions = best_model.predict(X_test_final)

# Evaluation
print("Final Test Accuracy:", accuracy_score(y_test_final, test_predictions))
print(classification_report(y_test_final, test_predictions))

# Optional: readable labels
test_df['predicted_sentiment'] = test_predictions
test_df['predicted_sentiment'] = test_df['predicted_sentiment'].map({
    0: 'negative',
    1: 'neutral',
    2: 'positive'
})

test_df[['text', 'predicted_sentiment']].head()

test_df['sentiment'].isna().sum()



test_df['predicted_sentiment'] = test_predictions

test_df['predicted_sentiment'] = test_df['predicted_sentiment'].map({
    0: 'negative',
    1: 'neutral',
    2: 'positive'
})

test_df[['text', 'predicted_sentiment']].head()

test_df = test_df.dropna(subset=['sentiment'])

y_test_final = test_df['sentiment']
X_test_final = vectorizer.transform(test_df['clean_text'])

test_predictions = best_model.predict(X_test_final)

print("Final Test Accuracy:", accuracy_score(y_test_final, test_predictions))
print(classification_report(y_test_final, test_predictions))



"""try to increase accuracy"""

from sklearn.model_selection import GridSearchCV
from sklearn.svm import LinearSVC

param_grid = {
    'C': [0.01, 0.1, 1, 5, 10]
}

svm = LinearSVC()

grid = GridSearchCV(
    svm,
    param_grid,
    cv=5,
    scoring='f1_macro',
    n_jobs=-1
)

grid.fit(X_train_tfidf, y_train)

best_svm = grid.best_estimator_
print("Best C:", grid.best_params_)

y_pred = best_svm.predict(X_test_tfidf)
print(classification_report(y_test, y_pred))

vectorizer = TfidfVectorizer(
    max_features=15000,
    ngram_range=(1,3),
    min_df=3,
    sublinear_tf=True
)

print(X_train_tfidf.shape)
print(X_test_tfidf.shape)

"""checking wheater model Accuracy comparison chart (LR vs NB vs SVM) did we done this"""

for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    preds = model.predict(X_test_tfidf)
    acc = accuracy_score(y_test, preds)
    print(f"{name} Accuracy: {acc:.4f}")

accuracies = {}

for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    preds = model.predict(X_test_tfidf)
    acc = accuracy_score(y_test, preds)
    accuracies[name] = acc

import matplotlib.pyplot as plt

model_names = list(accuracies.keys())
accuracy_values = list(accuracies.values())

plt.figure()
plt.bar(model_names, accuracy_values)
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Accuracy Comparison: LR vs NB vs SVM")
plt.show()

"""website deployment"""

!pip install streamlit joblib nltk pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import joblib
# import re
# import nltk
# import numpy as np
# from nltk.corpus import stopwords
# 
# nltk.download('stopwords')
# 
# model = joblib.load("best_sentiment_model.pkl")
# vectorizer = joblib.load("tfidf_vectorizer.pkl")
# 
# stop_words = set(stopwords.words('english'))
# 
# def clean_text(text):
#     text = text.lower()
#     text = re.sub(r'[^a-zA-Z]', ' ', text)
#     text = text.split()
#     text = [w for w in text if w not in stop_words]
#     return ' '.join(text)
# 
# st.title("ðŸ’¬ Sentiment Analysis Web App")
# 
# user_input = st.text_area("Enter text")
# 
# if st.button("Analyze Sentiment"):
#     if user_input.strip() == "":
#         st.warning("Please enter some text")
#     else:
#         cleaned = clean_text(user_input)
#         vector = vectorizer.transform([cleaned])
# 
#         prediction = model.predict(vector)[0]
#         decision_scores = model.decision_function(vector)
# 
#         confidence = np.max(decision_scores)
#         confidence_pct = round(
#             (confidence / np.sum(np.abs(decision_scores))) * 100, 2
#         )
# 
#         if prediction == 0:
#             st.error("ðŸ˜  Negative")
#         elif prediction == 1:
#             st.info("ðŸ˜ Neutral")
#         else:
#             st.success("ðŸ˜Š Positive")
# 
#

!pip install streamlit pyngrok joblib nltk

!streamlit run app.py &>/content/logs.txt &

from pyngrok import ngrok
ngrok.set_auth_token("38ElXPoPDWwS6L6wyNPytnmQO7q_3YNpKpBpcffyugn98LYaF")

from pyngrok import ngrok
public_url = ngrok.connect(8501)
print(public_url)

